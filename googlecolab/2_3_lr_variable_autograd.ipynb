{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. import required libraries**"
      ],
      "metadata": {
        "id": "jXCjFWwk91sd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8OrK-UdS7wZz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Tensor vs Variable**\n",
        "\n",
        "**1) Declaration**"
      ],
      "metadata": {
        "id": "uzSfGBqH-vj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_tensor = torch.Tensor(3,4)\n",
        "x_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Useb93sM-cqe",
        "outputId": "97f11168-a0a6-4567-ee2d-55ec37eb119c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.4729e+07, 4.4386e-41, 1.5362e+07, 4.4386e-41],\n",
              "        [1.5362e+07, 4.4386e-41, 1.5362e+07, 4.4386e-41],\n",
              "        [1.5362e+07, 4.4386e-41, 1.5362e+07, 4.4386e-41]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_variable = Variable(x_tensor)\n",
        "x_variable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIe771mS_Qpg",
        "outputId": "ca5331c4-a275-48e2-c379-75f4cb797f16"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.4729e+07, 4.4386e-41, 1.5362e+07, 4.4386e-41],\n",
              "        [1.5362e+07, 4.4386e-41, 1.5362e+07, 4.4386e-41],\n",
              "        [1.5362e+07, 4.4386e-41, 1.5362e+07, 4.4386e-41]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variable 은 autogradient 가능함<br>\n",
        "Pytorch 0.4 이상 버전에서는 Tensor에 Variable이 통합되고, Variable은\n",
        "deprecated임.<br>Tensor만 사용"
      ],
      "metadata": {
        "id": "1l80g0Fq_yCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Variable of a Variable**"
      ],
      "metadata": {
        "id": "t6wM920ZAmem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data 속성\n",
        "x_variable.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06wYYGoVASfv",
        "outputId": "6ebbea34-fb5d-4028-ec9e-f05bb976ccaa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.4729e+07, 4.4386e-41, 1.5362e+07, 4.4386e-41],\n",
              "        [1.5362e+07, 4.4386e-41, 1.5362e+07, 4.4386e-41],\n",
              "        [1.5362e+07, 4.4386e-41, 1.5362e+07, 4.4386e-41]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grad 속성 : 값에 대한 gradient\n",
        "# Variable 생성시 초기화되면서, gradient 도 같이 정의됨\n",
        "print(x_variable.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da9B99wTAPfG",
        "outputId": "ccbbb404-a38b-4074-8157-578065e2f275"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# requires_grad 속성 : 값에 대한 gradient 요구시 사용함\n",
        "print(x_variable.requires_grad) # 속성의 설정값 확인 : False\n",
        "# gradient 가 계산이 안된 상태임"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHF0XhxyBdky",
        "outputId": "a634499c-92c0-4e9e-fdb6-2b6717db9ca5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient 에 대한 연산을 수행하게 함 : True\n",
        "x_variable = Variable(x_tensor, requires_grad=True)\n",
        "x_variable.requires_grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UJwjo-CCNQn",
        "outputId": "b2fc1c2d-9e25-4b91-891a-336b3a8d750f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# volatile 속성 : 최소 메모리 사용에 대한 설정\n",
        "# requires_grad 가 False이면, volatile 도 자동 False가 됨\n",
        "x_variable = Variable(x_tensor, requires_grad = True)\n",
        "x_variable.grad, x_variable.requires_grad, x_variable.volatile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA2ZFQbbCxTn",
        "outputId": "bead11b9-9c02-450a-eac7-ae197bcb0ad9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-76461c3c011b>:4: UserWarning: volatile was removed (Variable.volatile is always False)\n",
            "  x_variable.grad, x_variable.requires_grad, x_variable.volatile\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, True, False)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Graph & Variables**"
      ],
      "metadata": {
        "id": "d7SLgHN9D5gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create graph\n",
        "x = Variable(torch.FloatTensor(3,4), requires_grad=True)\n",
        "y = x**2 + 4*x\n",
        "z = 2*y + 3\n",
        "\n",
        "x.requires_grad, y.requires_grad, z.requires_grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3qfXJwuEJHG",
        "outputId": "5fbaab1a-6d38-4354-ea25-d65ce899af88"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True, True)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "backword(gradient, retain_graph, create_graph, retain_variables)\n",
        "현재 값 w, r, t, graph 에 대한 gradient 계산 함수임\n",
        "역전파 알고리즘 적용된 계산함수임"
      ],
      "metadata": {
        "id": "A1VfoUURFDKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 위의 z 값으로 x의 gradient 를 계산해 냄\n",
        "loss = torch.FloatTensor(3,4)\n",
        "z.backward(loss)\n",
        "\n",
        "print(x.grad)\n",
        "y.grad, z.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM3w3s2mESKe",
        "outputId": "9c5b3284-1a29-4eb8-d4ec-2941c41a9423"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.0223e+08,  3.5509e-40, -8.9486e+20,  2.4784e-40],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  5.6052e-44,  6.1642e+32,  5.7718e+23]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-f26e95b4536c>:6: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  y.grad, z.grad\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}